{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Development Template\n",
    "Thomas Crosley, October 2017\n",
    "\n",
    "This is a template for developing TensorFlow models using several high-level APIs.\n",
    "<ul>\n",
    "    <li><a href=''></a></li>\n",
    "    <li><a href='https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator'>Estimators</a> --- <a href='https://www.tensorflow.org/extend/estimators'>Creating Estimators</a></li>  \n",
    "    <li><a href='https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment'>Experiment</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "tf.set_random_seed(0) # Graph level random seed\n",
    "np.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "train_file = 'train.tfrecord'\n",
    "valid_file = 'valid.tfrecord'\n",
    "\n",
    "ts = time.time()\n",
    "timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "output_dir = '/tmp/' + timestamp\n",
    "\n",
    "hyper_params = {'batch_size' : 32, 'learning_rate': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "def parser(record):\n",
    "    # Parse the TF record\n",
    "    parsed = tf.parse_single_example(record, features={})\n",
    "\n",
    "    # Load the data and format it\n",
    "    \n",
    "    # Data augmentation\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_dataset(tfrecord):\n",
    "    # Load the dataset\n",
    "    dataset = tf.contrib.data.TFRecordDataset(tfrecord)\n",
    "\n",
    "    # Parse the tf record entries\n",
    "    dataset = dataset.map(parser, num_threads=8, output_buffer_size=1024)\n",
    "\n",
    "    # Shuffle the data, batch it and run this for multiple epochs\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset\n",
    "\n",
    "train_data = load_dataset(train_file)\n",
    "valid_data = load_dataset(valid_file)\n",
    "\n",
    "\n",
    "def train_input_fn():\n",
    "    \n",
    "\n",
    "def eval_input_fn():\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "tf.reset_default_graph() # Useful if developing in Jupyter to clear previous test\n",
    "\n",
    "'''\n",
    "    Defines the model function passed into tf.estimator\n",
    "\n",
    "    1. Configure the model via TensorFlow operations\n",
    "    2. Define the loss function for training/evaluation\n",
    "    3. Define the training operation/optimizer\n",
    "    4. Generate predictions\n",
    "    5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "\n",
    "    Inputs:\n",
    "        features: A dict containing the features passed to the model via input_fn\n",
    "        labels: A Tensor containing the labels passed to the model via input_fn\n",
    "        mode: One of the following tf.estimator.ModeKeys string values indicating\n",
    "               the context in which the model_fn was invoked \n",
    "                  - tf.estimator.ModeKeys.TRAIN ---> est.train()\n",
    "                  - tf.estimator.ModeKeys.EVAL, ---> est.evaluate()\n",
    "                  - tf.estimator.ModeKeys.PREDICT -> est.predict()\n",
    "\n",
    "    Outputs:\n",
    "        tf.EstimatorSpec that defines the model\n",
    "'''\n",
    "def model(features, labels, mode, params):\n",
    "    # 1. Define model structure\n",
    "    # ...\n",
    "    predictions_dict = {'output': output}\n",
    "    \n",
    "    # 2. Define the loss functions\n",
    "    loss = ...\n",
    "    \n",
    "    # 2.1 Additional metrics for evaluation\n",
    "    eval_metric_ops = {\"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(labels, tf.float64), output)}\n",
    "    \n",
    "    # 3. Define optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # 4. Generate predictions\n",
    "    predictions = output\n",
    "    \n",
    "    # 5. Return EstimatorSpec\n",
    "    return EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)\n",
    "    \n",
    "estimator = tf.estimator(model_fn=model, model_dir=output_dir, config=config, params=hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard\n",
    "merged_summary = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(output_dir + '/TB/train', tf.get_default_graph())\n",
    "valid_writer = tf.summary.FileWriter(output_dir + '/TB/valid', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session setup\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "experiment = tf.contrib.learn.Experiment(\n",
    "    estimator=estimator,\n",
    "    train_input_fn=train_input_fn,\n",
    "    eval_input_fn=eval_input_fn,\n",
    "    train_steps=params.train_steps,  # Minibatch steps\n",
    "    min_eval_frequency=params.min_eval_frequency,  # Eval frequency\n",
    "    train_monitors=[train_input_hook],  # Hooks for training\n",
    "    eval_hooks=[eval_input_hook],  # Hooks for evaluation\n",
    "    eval_steps=None  # Use evaluation feeder until its empty\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extra files for reproducibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
